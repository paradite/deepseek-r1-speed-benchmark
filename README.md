# DeepSeek R1 speed benchmark

Code for benchmarking the speed of DeepSeek R1 from different providers' APIs.

Read the full report: [DeepSeek R1: Comparing Pricing and Speed Across Providers](https://prompt.16x.engineer/blog/deepseek-r1-cost-pricing-speed)

## Providers

Currently supported:

- [DeepSeek](https://www.deepseek.com/)
- [DeepInfra](https://deepinfra.com/)
- [Fireworks](https://fireworks.ai/)
- [Together](https://www.together.ai/)
- [Chutes](https://chutes.ai/)
- [Hyperbolic](https://hyperbolic.xyz/)
- [Azure AI Foundry](https://azure.microsoft.com/en-us/products/ai-foundry)
- [Nebius](https://nebius.com/)

TODO:

- [Nvidia NIM](https://build.nvidia.com/deepseek-ai/deepseek-r1)

Providers that I am not able to test due to high costs or lack of open access:

- [Awesome Cloud](https://awesomecloud.ai/secure-deepseek-r1/) (Contact sales)
- [AWS Bedrock](https://aws.amazon.com/blogs/aws/deepseek-r1-models-now-available-on-aws/) (Requires dedicated ec2 instance)
- [featherless](https://featherless.ai/#pricing) (Requires subscription)
- [Avian](https://avian.io/) (Requires dedicated deployment with 4 GPUs)

Watch list for DeepSeek R1 support:

- [Groq](https://www.groq.com/)
- [Cerebras](https://cerebras.ai/)

## Speed statistics

Statistics of the speed of the API automatically generated by running `analyze-speed.js`.

```
=== Overall Speed Statistics (tokens/second) ===
Using latest 22 benchmark runs

DeepSeek  : Median: 23.51, Mean: 31.72, Min/Max: 11.28/67.60, Success/Error: 16/0
Fireworks : Median: 17.76, Mean: 19.09, Min/Max: 6.77/47.71, Success/Error: 16/0
Hyperbolic: Median: 14.23, Mean: 15.47, Min/Max: 5.65/31.26, Success/Error: 10/1
Together  : Median: 11.52, Mean: 13.73, Min/Max: 7.57/21.72, Success/Error: 16/0
DeepInfra : Median: 7.64, Mean: 7.53, Min/Max: 3.09/9.76, Success/Error: 16/0
Azure     : Median: 5.49, Mean: 4.81, Min/Max: 1.89/6.90, Success/Error: 8/0
Nebius    : Median: 5.47, Mean: 6.39, Min/Max: 4.10/10.51, Success/Error: 4/0

=== Daily Statistics ===

Date: 1/31/2025
DeepSeek  : Median: 40.76, Mean: 42.95, Min/Max: 22.67/67.60, Success/Error: 4/0
Fireworks : Median: 23.50, Mean: 26.99, Min/Max: 13.24/47.71, Success/Error: 4/0
Together  : Median: 19.30, Mean: 18.67, Min/Max: 15.44/20.66, Success/Error: 4/0
Hyperbolic: Median: 6.56, Mean: 9.16, Min/Max: 5.65/15.28, Success/Error: 3/1
DeepInfra : Median: 5.53, Mean: 5.65, Min/Max: 3.09/8.45, Success/Error: 4/0
Nebius    : Median: 5.47, Mean: 6.39, Min/Max: 4.10/10.51, Success/Error: 4/0
Azure     : Median: 4.38, Mean: 4.39, Min/Max: 1.89/6.90, Success/Error: 4/0

Date: 1/30/2025
Fireworks : Median: 20.39, Mean: 17.56, Min/Max: 6.77/21.41, Success/Error: 6/0
DeepSeek  : Median: 20.30, Mean: 23.64, Min/Max: 11.28/46.72, Success/Error: 6/0
Together  : Median: 15.54, Mean: 15.03, Min/Max: 8.69/21.72, Success/Error: 6/0
Hyperbolic: Median: 13.19, Mean: 16.31, Min/Max: 7.21/31.26, Success/Error: 5/0
DeepInfra : Median: 7.22, Mean: 7.33, Min/Max: 6.87/7.89, Success/Error: 6/0
Azure     : Median: 5.49, Mean: 5.22, Min/Max: 3.97/5.95, Success/Error: 4/0

Date: 1/29/2025
DeepSeek  : Median: 27.48, Mean: 32.31, Min/Max: 15.80/67.60, Success/Error: 6/0
Hyperbolic: Median: 22.84, Mean: 22.84, Min/Max: 20.22/25.47, Success/Error: 2/0
Fireworks : Median: 15.04, Mean: 15.36, Min/Max: 11.79/20.32, Success/Error: 6/0
DeepInfra : Median: 9.37, Mean: 8.98, Min/Max: 6.61/9.76, Success/Error: 6/0
Together  : Median: 9.09, Mean: 9.15, Min/Max: 7.57/10.52, Success/Error: 6/0
```

## Sample output for a single run

```
=== Final Benchmark Results ===
Current time: 2025-01-30T07:23:37.790Z
Test prompt: What is the capital of France?

DeepSeek  : Speed: 24.34 tokens/s, Total: 424 tokens, Prompt: 12 tokens, Completion: 412 tokens, Time: 16.93s, Latency: 1.11s, Length: 1904 chars
Fireworks : Speed: 21.41 tokens/s, Total: 373 tokens, Prompt: 10 tokens, Completion: 363 tokens, Time: 16.96s, Latency: 2.16s, Length: 1785 chars
Together  : Speed: 18.65 tokens/s, Total: 393 tokens, Prompt: 10 tokens, Completion: 383 tokens, Time: 20.54s, Latency: 0.56s, Length: 1782 chars
DeepInfra : Speed: 6.87 tokens/s, Total: 73 tokens, Prompt: 10 tokens, Completion: 63 tokens, Time: 9.16s, Latency: 1.04s, Length: 297 chars
Azure     : Speed: 5.54 tokens/s, Total: 372 tokens, Prompt: 10 tokens, Completion: 362 tokens, Time: 65.34s, Latency: 5.35s, Length: 1783 chars
```

Full outputs:

- Check [outputs](outputs) directory for full outputs

## Missing data for some providers

A timeout of 10 seconds is used for all providers.

If the API does not respond within 10 seconds, the provider is skipped for that run.

This is why some providers are missing data.

## Setup

1. Install dependencies:

```bash
npm install
```

2. Create a `.env` file in the root directory.

Follow the sample in the `.env.example` file to set up your API keys.

3. Make sure you have Node.js version 20 or higher installed.

## Usage

Run the benchmark:

```bash
npm run benchmark        # Regular benchmark
npm run benchmark-show-output # Show the API response while benchmarking
npm run analyze-speed     # Analyze the speed of the API
```

The script will measure:

- Total tokens generated
- Response time
- First response latency
- Tokens per second
- Prompt and completion token counts

## How it works

The benchmark script sends a standardized prompt to the DeepSeek API and measures:

- The time taken to receive the complete response
- The number of tokens in both the prompt and response
- Calculates the overall tokens per second processing speed

This helps in understanding the real-world performance of the DeepSeek API in your specific environment and use case.
